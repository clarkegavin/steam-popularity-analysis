#pipelines:
#  - name: roblox_pipeline
#    enabled: true
#    class: DataExtractorPipeline       # which pipeline class to use
#    type: sample               # full or sample
#    sample_size: 100
#    output_csv: "roblox_data.csv"


pipelines:
  - name: roblox_extraction
    type: pipelines.data_extractor_pipeline.DataExtractorPipeline
    extractor_type: roblox
    params:
      output_csv: "output/roblox_data.csv"
#      extractor_params:
#        sample_size: 1000

# anything that changes the shape of teh data will need to be in this cleanup block
  - name: data_cleanup
    type: pipelines.data_cleanup_pipeline.DataCleanupPipeline
    params:
      # cleanup_steps is a list of preprocessors (built via PreprocessorFactory)
      cleanup_steps:
        - name: remove_duplicates
          params:
            field: "gameID"
            keep: "first"
            case_sensitive: false
            dropna: true
#        - name: filter_rows
#          params:
#            field: "Genre"
#            values: [ "All" ]
#            operator: "equals"
#            case_sensitive: false
        - name: filter_rows
          params:
            field: "Description"
            values: [null, ""]
            operator: "in"
            case_sensitive: false
        - name: merge_features
          params:
            columns: ["Description", "Title"]
            merge_to: "Description"
#        - name: remove_urls
#          params:
#            field: "Description"
#            pattern: 'https?://\S+|www\.\S+'
#        - name: remove_repeated_characters
#          params:
#            field: "Description"
#            pattern: "(.)\\1{2,}"
#        - name: remove_punctuation_noise
#          params:
#            field: "Description"
#            pattern: '([!?.,])\1+'
#        - name: remove_whitespace
#          params:
#            field: "Description"



  - name: filter_features
    type: pipelines.filter_pipeline.FilterPipeline
    filter_features:
      - name: drop_columns
        params:
          columns_to_drop:
            [ 'Id', 'Date', 'Active_Users', 'Favorites', 'Total_Visits',
              'Date_Created', 'Last_Updated', 'Server_Size', 'Title',
              'Creator', 'gameID', 'Category', 'URL' ]

  - name: eda
    type: pipelines.eda_pipeline.EDAPipeline
    params:
      save_path: "output/eda"
      steps:
        - name: class_balance
#        - name: wordcloud_global
#        - name: wordcloud_by_class
#        - name: duplicate_check
    #dataset:
      target: "Genre"
      text_field: "Description"

  - name: preprocess_text
    type: pipelines.preprocessing_pipeline.PreprocessingPipeline
    params:
      text_field: "Description"
      #      preprocessors: []
      preprocessors:
#        - name: filter_rows
#          params:
#            field: "Genre"
#            values: ["All"]
#            operator: "equals"
        - name: mask_genre_words
          params:
            description_field: "Description"
            genre_words: [ "RPG", "Comedy", "Adventure", "Horror", "Sci-Fi", "Fighting", "Military", "Naval", "Town", "City", "Town and City", "Building", "Build", "Builds", "Builder", "Builders", "Fight", "FPS" ]
            mask_token: "<MASKED>"
            case_sensitive: false


  - name: split_data
    type: pipelines.data_splitter_pipeline.DataSplitterPipeline
    params:
      target_column: "Genre"
      test_size: 0.2
      random_state: 42


  - name: encode_target
    type: pipelines.target_feature_pipeline.TargetFeaturePipeline
    params:
      target_column: "Genre"


    #------------------------------------------------------------
    # Experiment Pipelines
    #------------------------------------------------------------
  - name: naive_bayes
    type: pipelines.experiment_pipeline.ExperimentPipeline
    params:
      experiment_type: "classification"
      model_name: "naive_bayes"
      evaluator_name: "classification"
      metrics: ["accuracy", "f1_score", "precision", "recall"]
      mlflow_experiment: "Naive Bayes Experiments"
      experiments:
        # ------------------------------------------------------------
        # 1a. Naive Bayes + TF-IDF with word n-grams baseline
        # ------------------------------------------------------------
        - run_name: "1a. Naive Bayes + TF-IDF with word n-grams baseline"
          params:
            description: "1a. Naive Bayes + TF-IDF with word n-grams baseline"
            save_path: "output/naive_bayes_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 43
            vectorizer:
              vectorizer_name: "tfidf"
              vectorizer_field: "Description"
              vectorizer_params:
                max_features: 5000
                ngram_range: [1, 2]
                stop_words: "english"
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [ 8, 6 ]
                  cmap: "Blues"

        # ------------------------------------------------------------
        # 1b. Naive Bayes + TF-IDF with character n-grams and data cleansing
        # ------------------------------------------------------------
        - run_name: "1b. Naive Bayes TF-IDF"
          text_field: "Description"
          preprocessing:
            - name: lowercase
            - name: remove_repeated_characters
              params:
                field: "Description"
                pattern: "(.)\\1{2,}"
            - name: remove_urls
              params:
                field: "Description"
                pattern: 'https?://\S+|www\.\S+'
            - name: remove_whitespace
              params:
                field: "Description"
                pattern: '\\s+'
            - name: remove_punctuation_noise
              params:
                field: "Description"
                pattern: '([!?.,])\\1+'
            - name: emoji_remover
              params:
                use_emoji_lib: true
          params:
            description: "1b. Naive Bayes + TF-IDF with character n-grams and data cleansing"
            save_path: "output/naive_bayes_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 43
            vectorizer:
              vectorizer_name: "tfidf"
              vectorizer_field: "Description"
              vectorizer_params:
                max_features: 5000
                ngram_range: [4, 6]
                analyzer: 'char_wb'
                lowercase: true
                #stop_words: "english"
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [ 8, 6 ]
                  cmap: "Blues"

        # ------------------------------------------------------------
        # 1c Naive Bayes + TF-IDF with data cleansing character n-grams but no emoji removal
        # ------------------------------------------------------------
        - run_name: "1c. Naive Bayes TF-IDF"
          text_field: "Description"
          preprocessing:
            - name: lowercase
            - name: remove_repeated_characters
              params:
                field: "Description"
                pattern: "(.)\\1{2,}"
            - name: remove_urls
              params:
                field: "Description"
                pattern: 'https?://\S+|www\.\S+'
            - name: remove_whitespace
              params:
                field: "Description"
                pattern: '\\s+'
            - name: remove_punctuation_noise
              params:
                field: "Description"
                pattern: '([!?.,])\\1+'
#            - name: emoji_remover
#              params:
#                use_emoji_lib: true
          params:
            description: "1c Naive Bayes + TF-IDF with data cleansing character n-grams but no emoji removal"
            save_path: "output/naive_bayes_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 43
            vectorizer:
              vectorizer_name: "tfidf"
              vectorizer_field: "Description"
              vectorizer_params:
                max_features: 5000
                ngram_range: [ 4, 6 ]
                analyzer: 'char_wb'
                lowercase: true
                #stop_words: "english"
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [ 8, 6 ]
                  cmap: "Blues"

        # ------------------------------------------------------------
        # 1d Naive Bayes + TF-IDF with data cleansing character n-grams but no emoji removal and increase max features to 10000
        # ------------------------------------------------------------
        - run_name: "1d. Naive Bayes TF-IDF"
          text_field: "Description"
          preprocessing:
            - name: lowercase
            - name: remove_repeated_characters
              params:
                field: "Description"
                pattern: "(.)\\1{2,}"
            - name: remove_urls
              params:
                field: "Description"
                pattern: 'https?://\S+|www\.\S+'
            - name: remove_whitespace
              params:
                field: "Description"
                pattern: '\\s+'
            - name: remove_punctuation_noise
              params:
                field: "Description"
                pattern: '([!?.,])\\1+'
        #            - name: emoji_remover
        #              params:
        #                use_emoji_lib: true
          params:
            description: "1d Naive Bayes + TF-IDF with data cleansing character n-grams but no emoji removal and increase max features to 10000"
            save_path: "output/naive_bayes_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 43
            vectorizer:
              vectorizer_name: "tfidf"
              vectorizer_field: "Description"
              vectorizer_params:
                max_features: 10000
                ngram_range: [ 4, 6 ]
                analyzer: 'char_wb'
                lowercase: true
                #stop_words: "english"
          visualisations:
            - name: confusion_matrix
              kwargs:
                figsize: [ 8, 6 ]
                cmap: "Blues"

        # ------------------------------------------------------------
        # 2a. Naive Bayes + TF-IDF with Porter Stemming with character n-grams and data cleansing, emoji removal excluded, max features 10000 and no stop_words
        # ------------------------------------------------------------
        - run_name: "2a. Naive Bayes TF-IDF (with Porter Stemming)"
          text_field: "Description"
          preprocessing:
            - name: lowercase
            - name: remove_repeated_characters
              params:
                field: "Description"
                pattern: "(.)\\1{2,}"
            - name: remove_urls
              params:
                field: "Description"
                pattern: 'https?://\S+|www\.\S+'
            - name: remove_whitespace
              params:
                field: "Description"
                pattern: '\\s+'
            - name: remove_punctuation_noise
              params:
                field: "Description"
                pattern: '([!?.,])\\1+'
  #            - name: emoji_remover
  #              params:
  #                use_emoji_lib: true
            - name: stemmer
              params:
                language: "english"
                algorithm: "porter"
          params:
            description: "2a. Naive Bayes + TF-IDF with Porter Stemming with character n-grams and data cleansing, emoji removal exluded, max features 10000 and no stop_words"
            save_path: "output/naive_bayes_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 43
            vectorizer:
              vectorizer_name: "tfidf"
              vectorizer_field: "Description"
              vectorizer_params:
                max_features: 10000
                ngram_range: [ 4, 6 ]
                analyzer: 'char_wb'
                #stop_words: "english"
                lowercase: true
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [ 8, 6 ]
                  cmap: "Blues"

        # ------------------------------------------------------------
        # 2b. Naive Bayes + TF-IDF with Porter Stemming with character n-grams and data cleansing, emoji removal excluded, max features 10000 and  stop_words before stemming
        # ------------------------------------------------------------
        - run_name: "2b. Naive Bayes TF-IDF (with Porter Stemming)"
          text_field: "Description"
          preprocessing:
            - name: lowercase
            - name: remove_repeated_characters
              params:
                field: "Description"
                pattern: "(.)\\1{2,}"
            - name: remove_urls
              params:
                field: "Description"
                pattern: 'https?://\S+|www\.\S+'
            - name: remove_whitespace
              params:
                field: "Description"
                pattern: '\\s+'
            - name: remove_punctuation_noise
              params:
                field: "Description"
                pattern: '([!?.,])\\1+'
            - name: stopword_remover
              params:
                language: "english"
                lower: true
  #            - name: emoji_remover
  #              params:
  #                use_emoji_lib: true
            - name: stemmer
              params:
                language: "english"
                algorithm: "porter"
          params:
            description: "2b. Naive Bayes + TF-IDF with Porter Stemming with character n-grams and data cleansing, emoji removal excluded, max features 10000 and  stop_words before stemming"
            save_path: "output/naive_bayes_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 43
            vectorizer:
              vectorizer_name: "tfidf"
              vectorizer_field: "Description"
              vectorizer_params:
                max_features: 10000
                ngram_range: [ 4, 6 ]
                analyzer: 'char_wb'
                #stop_words: "english"
                lowercase: true
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [ 8, 6 ]
                  cmap: "Blues"

        # ------------------------------------------------------------
        # 2c. Naive Bayes + TF-IDF with Porter Stemming with character n-grams and data cleansing, emoji removal excluded, max features 10000 and  stop_words after stemming
        # ------------------------------------------------------------
        - run_name: "2c. Naive Bayes TF-IDF (with Porter Stemming)"
          text_field: "Description"
          preprocessing:
            - name: lowercase
            - name: remove_repeated_characters
              params:
                field: "Description"
                pattern: "(.)\\1{2,}"
            - name: remove_urls
              params:
                field: "Description"
                pattern: 'https?://\S+|www\.\S+'
            - name: remove_whitespace
              params:
                field: "Description"
                pattern: '\\s+'
            - name: remove_punctuation_noise
              params:
                field: "Description"
                pattern: '([!?.,])\\1+'
#            - name: stopword_remover
#              params:
#                language: "english"
#                lower: true
  #            - name: emoji_remover
  #              params:
  #                use_emoji_lib: true
            - name: stemmer
              params:
                language: "english"
                algorithm: "porter"
          params:
            description: "2c. Naive Bayes + TF-IDF with Porter Stemming with character n-grams and data cleansing, emoji removal excluded, max features 10000 and  stop_words after stemming"
            save_path: "output/naive_bayes_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 43
            vectorizer:
              vectorizer_name: "tfidf"
              vectorizer_field: "Description"
              vectorizer_params:
                max_features: 10000
                ngram_range: [ 4, 6 ]
                analyzer: 'char_wb'
                stop_words: "english"
                lowercase: true
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [ 8, 6 ]
                  cmap: "Blues"

        # ------------------------------------------------------------
        # 3a. Naive Bayes + TF-IDF with Snowball Stemming with character n-grams and data cleansing, emoji removal excluded,, max features 10000 and  no stop_words
        # -----------------------------------------------------------
        - run_name: "3a. Naive Bayes TF-IDF (with Snowball Stemming)"
          text_field: "Description"
          preprocessing:
            - name: lowercase
            - name: remove_repeated_characters
              params:
                field: "Description"
                pattern: "(.)\\1{2,}"
            - name: remove_urls
              params:
                field: "Description"
                pattern: 'https?://\S+|www\.\S+'
            - name: remove_whitespace
              params:
                field: "Description"
                pattern: '\\s+'
            - name: remove_punctuation_noise
              params:
                field: "Description"
                pattern: '([!?.,])\\1+'
#          - name: stopword_remover
#            params:
#              language: "english"
#              lower: true
#          - name: emoji_remover
#            params:
#              use_emoji_lib: true
            - name: stemmer
              params:
                language: "english"
                algorithm: "snowball"
          params:
            description: "3a. Naive Bayes + TF-IDF with Snowball Stemming with character n-grams and data cleansing, emoji removal excluded, max features 10000 and  no stop_words"
            save_path: "output/naive_bayes_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 43
            vectorizer:
              vectorizer_name: "tfidf"
              vectorizer_field: "Description"
              vectorizer_params:
                max_features: 10000
                ngram_range: [ 4, 6 ]
                analyzer: 'char_wb'
                #stop_words: "english"
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [ 8, 6 ]
                  cmap: "Blues"

        # ------------------------------------------------------------
        # 3b. Naive Bayes + TF-IDF with Snowball Stemming with character n-grams and data cleansing, emoji removal excluded,, max features 10000 and  stop_words before stemming
        # -----------------------------------------------------------
        - run_name: "3b. Naive Bayes TF-IDF (with Snowball Stemming)"
          text_field: "Description"
          preprocessing:
            - name: lowercase
            - name: remove_repeated_characters
              params:
                field: "Description"
                pattern: "(.)\\1{2,}"
            - name: remove_urls
              params:
                field: "Description"
                pattern: 'https?://\S+|www\.\S+'
            - name: remove_whitespace
              params:
                field: "Description"
                pattern: '\\s+'
            - name: remove_punctuation_noise
              params:
                field: "Description"
                pattern: '([!?.,])\\1+'
            - name: stopword_remover
              params:
                language: "english"
                lower: true
            #          - name: emoji_remover
            #            params:
            #              use_emoji_lib: true
            - name: stemmer
              params:
                language: "english"
                algorithm: "snowball"
          params:
            description: "3b. Naive Bayes + TF-IDF with Snowball Stemming with character n-grams and data cleansing, emoji removal excluded,, max features 10000 and  stop_words before stemming"
            save_path: "output/naive_bayes_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 43
            vectorizer:
              vectorizer_name: "tfidf"
              vectorizer_field: "Description"
              vectorizer_params:
                max_features: 10000
                ngram_range: [ 4, 6 ]
                analyzer: 'char_wb'
                #stop_words: "english"
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [ 8, 6 ]
                  cmap: "Blues"

        # ------------------------------------------------------------
        # 3c. Naive Bayes + TF-IDF with Snowball Stemming with character n-grams and data cleansing, emoji removal excluded, max features 10000 and  stop_words after stemming
        # -----------------------------------------------------------
        - run_name: "3c. Naive Bayes TF-IDF (with Snowball Stemming)"
          text_field: "Description"
          preprocessing:
            - name: lowercase
            - name: remove_repeated_characters
              params:
                field: "Description"
                pattern: "(.)\\1{2,}"
            - name: remove_urls
              params:
                field: "Description"
                pattern: 'https?://\S+|www\.\S+'
            - name: remove_whitespace
              params:
                field: "Description"
                pattern: '\\s+'
            - name: remove_punctuation_noise
              params:
                field: "Description"
                pattern: '([!?.,])\\1+'
#            - name: stopword_remover
#              params:
#                language: "english"
#                lower: true
            #          - name: emoji_remover
            #            params:
            #              use_emoji_lib: true
            - name: stemmer
              params:
                language: "english"
                algorithm: "snowball"
          params:
            description: "3c. Naive Bayes + TF-IDF with Snowball Stemming with character n-grams and data cleansing, emoji removal excluded, max features 10000 and  stop_words after stemming"
            save_path: "output/naive_bayes_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 43
            vectorizer:
              vectorizer_name: "tfidf"
              vectorizer_field: "Description"
              vectorizer_params:
                max_features: 10000
                ngram_range: [ 4, 6 ]
                analyzer: 'char_wb'
                stop_words: "english"
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [ 8, 6 ]
                  cmap: "Blues"

        # ------------------------------------------------------------
        # 4a. Naive Bayes + TF-IDF with Lemmatization with character n-grams and data cleansing, emoji removal excluded, max features 10000 and no stop_words
        # ------------------------------------------------------------
        - run_name: "4a. Naive Bayes TF-IDF (with Lemmatization)"
          text_field: "Description"
          preprocessing:
            - name: lowercase
            - name: remove_repeated_characters
              params:
                field: "Description"
                pattern: "(.)\\1{2,}"
            - name: remove_urls
              params:
                field: "Description"
                pattern: 'https?://\S+|www\.\S+'
            - name: remove_whitespace
              params:
                field: "Description"
                pattern: '\\s+'
            - name: remove_punctuation_noise
              params:
                field: "Description"
                pattern: '([!?.,])\\1+'
              #            - name: stopword_remover
              #              params:
              #                language: "english"
              #                lower: true
              #          - name: emoji_remover
              #            params:
              #              use_emoji_lib: true
            - name: lemmatizer
              params:
                model: "en_core_web_sm"
          params:
            description: "4a. Naive Bayes + TF-IDF with Lemmatization with character n-grams and data cleansing, emoji removal excluded, max features 10000 and no stop_words"
            save_path: "output/naive_bayes_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 43
            vectorizer:
              vectorizer_name: "tfidf"
              vectorizer_field: "Description"
              vectorizer_params:
                max_features: 10000
                ngram_range: [ 4, 6 ]
                analyzer: 'char_wb'
                #stop_words: "english"
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [ 8, 6 ]
                  cmap: "Blues"

        # ------------------------------------------------------------
        # 4b. Naive Bayes + TF-IDF with Lemmatization with character n-grams and data cleansing, emoji removal excluded, max features 10000 and stop_words before lemmatization
        # ------------------------------------------------------------
        - run_name: "4b. Naive Bayes TF-IDF (with Lemmatization)"
          text_field: "Description"
          preprocessing:
            - name: lowercase
            - name: remove_repeated_characters
              params:
                field: "Description"
                pattern: "(.)\\1{2,}"
            - name: remove_urls
              params:
                field: "Description"
                pattern: 'https?://\S+|www\.\S+'
            - name: remove_whitespace
              params:
                field: "Description"
                pattern: '\\s+'
            - name: remove_punctuation_noise
              params:
                field: "Description"
                pattern: '([!?.,])\\1+'
            - name: stopword_remover
              params:
                language: "english"
                lower: true
              #          - name: emoji_remover
              #            params:
              #              use_emoji_lib: true
            - name: lemmatizer
              params:
                model: "en_core_web_sm"
          params:
            description: "4b. Naive Bayes + TF-IDF with Lemmatization with character n-grams and data cleansing, emoji removal excluded, max features 10000 and stop_words before lemmatization"
            save_path: "output/naive_bayes_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 43
            vectorizer:
              vectorizer_name: "tfidf"
              vectorizer_field: "Description"
              vectorizer_params:
                max_features: 10000
                ngram_range: [ 4, 6 ]
                analyzer: 'char_wb'
                #stop_words: "english"
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [ 8, 6 ]
                  cmap: "Blues"

        # ------------------------------------------------------------
        # 4c. Naive Bayes + TF-IDF with Lemmatization with character n-grams and data cleansing, emoji removal excluded, max features 10000 and stop_words after lemmatization
        # ------------------------------------------------------------
        - run_name: "4c. Naive Bayes TF-IDF (with Lemmatization)"
          text_field: "Description"
          preprocessing:
            - name: lowercase
            - name: remove_repeated_characters
              params:
                field: "Description"
                pattern: "(.)\\1{2,}"
            - name: remove_urls
              params:
                field: "Description"
                pattern: 'https?://\S+|www\.\S+'
            - name: remove_whitespace
              params:
                field: "Description"
                pattern: '\\s+'
            - name: remove_punctuation_noise
              params:
                field: "Description"
                pattern: '([!?.,])\\1+'
              #            - name: stopword_remover
              #              params:
              #                language: "english"
              #                lower: true
              #          - name: emoji_remover
              #            params:
              #              use_emoji_lib: true
            - name: lemmatizer
              params:
                model: "en_core_web_sm"
          params:
            description: "4c. Naive Bayes + TF-IDF with Lemmatization with character n-grams and data cleansing, emoji removal excluded, max features 10000 and stop_words after lemmatization"
            save_path: "output/naive_bayes_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 43
            vectorizer:
              vectorizer_name: "tfidf"
              vectorizer_field: "Description"
              vectorizer_params:
                max_features: 10000
                ngram_range: [ 4, 6 ]
                analyzer: 'char_wb'
                stop_words: "english"
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [ 8, 6 ]
                  cmap: "Blues"

  #------------------------------------------------------------
  # Experiment Pipeline for KNN
  #------------------------------------------------------------

  - name: knn
    type: pipelines.experiment_pipeline.ExperimentPipeline
    params:
      experiment_type: "classification"
      model_name: "knn"
      evaluator_name: "classification"
      metrics: [ "accuracy", "f1_score", "precision", "recall" ]
      mlflow_experiment: "KNN Experiments"
      experiments:
        # ------------------------------------------------------------
        # 1. KNN + TF-IDF
        # ------------------------------------------------------------
        - run_name: "1a. KNN TF-IDF"
          params:
            n_neighbors: 5
            weights: "uniform"
            description: "KNN experiments with TF-IDF vectorization technique on Roblox game descriptions."
            save_path: "output/knn_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 42
            vectorizer:
              vectorizer_name: "tfidf"
              vectorizer_field: "Description"
              vectorizer_params:
                max_features: 10000
                ngram_range: [ 1, 2 ]
                stop_words: "english"
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [ 8, 6 ]
                  cmap: "Blues"
          # ------------------------------------------------------------
          # 1. KNN + Word2Vec
          # ------------------------------------------------------------
        - run_name: "1b. KNN Word2Vec"
          params:
            n_neighbors: 5
            weights: "uniform"
            description: "KNN experiments with Word2Vec vectorization technique on Roblox game descriptions."
            save_path: "output/knn_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 42
            vectorizer:
              vectorizer_name: "word2vec"
              vectorizer_field: "Description"
              vectorizer_params:
                vector_size: 100
                window: 3
                min_count: 2
                sg: 1
                workers: 4
                epochs: 25
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [ 8, 6 ]
                  cmap: "Blues"
        # ------------------------------------------------------------
        # 3. KNN + BERT
        # ------------------------------------------------------------
        - run_name: "1b. KNN BERT"
          params:
            n_neighbors: 5
            weights: "uniform"
            description: "KNN experiments with BERT embeddings on Roblox game descriptions."
            save_path: "output/knn_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 42
            vectorizer:
              vectorizer_name: "bert"
              vectorizer_field: "Description"
              vectorizer_params:
                model_name: "sentence-transformers/all-mpnet-base-v2"
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [ 8, 6 ]
                  cmap: "Blues"

  - name: xgboost
    type: pipelines.experiment_pipeline.ExperimentPipeline
    params:
      experiment_type: "classification"
      model_name: "xgboost"
      evaluator_name: "classification"
      metrics: [ "accuracy", "f1_score", "precision", "recall" ]
      mlflow_experiment: "XGBoost Experiments"
      experiments:
        # ------------------------------------------------------------
        # 1. XGBoost + TF-IDF
        # ------------------------------------------------------------
        - run_name: "1a. XGBoost TF-IDF"
          params:
            description: "XGBoost experiments with TF-IDF vectorization technique on Roblox game descriptions."
            save_path: "output/xgboost_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 42
            model_params: {}   # default XGBoost hyperparameters
            vectorizer:
              vectorizer_name: "tfidf"
              vectorizer_field: "Description"
              vectorizer_params:
                max_features: 5000
                ngram_range: [1, 2]
                stop_words: "english"
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [8, 6]
                  cmap: "Blues"

        # ------------------------------------------------------------
        # 2. XGBoost + Word2Vec
        # ------------------------------------------------------------
        - run_name: "1b. XGBoost Word2Vec"
          params:
            description: "XGBoost experiments with Word2Vec vectorization technique on Roblox game descriptions."
            save_path: "output/xgboost_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 42
            model_params: {}   # defaults
            vectorizer:
              vectorizer_name: "word2vec"
              vectorizer_field: "Description"
              vectorizer_params:
                vector_size: 300
                window: 5
                min_count: 2
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [8, 6]
                  cmap: "Blues"

        # ------------------------------------------------------------
        # 3. XGBoost + BERT
        # ------------------------------------------------------------
        - run_name: "1c. XGBoost BERT"
          params:
            description: "XGBoost experiments with BERT embeddings on Roblox game descriptions."
            save_path: "output/xgboost_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 42
            model_params: {}   # defaults
            vectorizer:
              vectorizer_name: "bert"
              vectorizer_field: "Description"
              vectorizer_params:
                model_name: "sentence-transformers/all-mpnet-base-v2"
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [8, 6]
                  cmap: "Blues"
  - name: svm
    type: pipelines.experiment_pipeline.ExperimentPipeline
    params:
      experiment_type: "classification"
      model_name: "svm"
      evaluator_name: "classification"
      metrics: [ "accuracy", "f1_score", "precision", "recall" ]
      mlflow_experiment: "SVM Experiments"
      experiments:
        # ------------------------------------------------------------
        # 1. SVM + TF-IDF
        # ------------------------------------------------------------
        - run_name: "1a. SVM TF-IDF"
          params:
            description: "SVM experiments with TF-IDF vectorization technique on Roblox game descriptions."
            save_path: "output/svm_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 42
            model_params:
              kernel: "linear"  # LinearSVC default
              C: 1.0
            vectorizer:
              vectorizer_name: "tfidf"
              vectorizer_field: "Description"
              vectorizer_params:
                max_features: 5000
                ngram_range: [1, 2]
                stop_words: "english"
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [8, 6]
                  cmap: "Blues"

        # ------------------------------------------------------------
        # 2. SVM + Word2Vec
        # ------------------------------------------------------------
        - run_name: "1b. SVM Word2Vec"
          params:
            description: "SVM experiments with Word2Vec embeddings on Roblox game descriptions."
            save_path: "output/svm_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 42
            model_params:
              kernel: "linear"
              C: 1.0
              # scale_features: true  # optional flag if your pipeline scales dense vectors
            vectorizer:
              vectorizer_name: "word2vec"
              vectorizer_field: "Description"
              vectorizer_params:
                vector_size: 300
                window: 5
                min_count: 2
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [8, 6]
                  cmap: "Blues"

        # ------------------------------------------------------------
        # 3. SVM + BERT
        # ------------------------------------------------------------
        - run_name: "1c. SVM BERT"
          params:
            description: "SVM experiments with BERT embeddings on Roblox game descriptions."
            save_path: "output/svm_results"
            cv_enabled: true
            cv_stratified: true
            cv_folds: 5
            cv_shuffle: true
            cv_random_state: 42
            model_params:
              kernel: "linear"
              C: 1.0
              # scale_features: true
            vectorizer:
              vectorizer_name: "bert"
              vectorizer_field: "Description"
              vectorizer_params:
                model_name: "sentence-transformers/all-mpnet-base-v2"
            visualisations:
              - name: confusion_matrix
                kwargs:
                  figsize: [8, 6]
                  cmap: "Blues"
