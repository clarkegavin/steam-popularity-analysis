#config/pipelines.yaml

pipelines:
  - name: steam_extraction
    type: pipelines.data_extractor_pipeline.DataExtractorPipeline
    extractor_type: steam
    params:
      output_csv: "output/steam_data.csv"
#      extractor_params:
#        sample_size: 1000

  - name: data_cleanup
    type: pipelines.data_cleanup_pipeline.DataCleanupPipeline
    params:
      # cleanup_steps is a list of preprocessors (built via PreprocessorFactory)
      cleanup_steps:
        - name: remove_duplicates
          params:
            field: "AppID"
            keep: "first"
            case_sensitive: false
            dropna: true
        - name: filter_rows
          params:
            field: "Release_Date"
            values: [ null ]
            operator: "in"
            case_sensitive: false

  - name: filter_features
    type: pipelines.filter_pipeline.FilterPipeline
    filter_features:
      - name: drop_columns
        params:
          columns_to_drop: [ 'Id', 'AppID', 'Name',  'Type', 'URL', 'Tags', 'Price_Currency', 'Review_Score_Desc', 'Metacritic_URL',
                             'Current_Players_Last_Updated', 'Content_Descriptors',
          #                   'Developers', 'Publishers'
          ]


  - name: eda #output correlations before exploding columns
    type: pipelines.eda_pipeline.EDAPipeline
    params:
      save_path: "output/eda"
      steps:
        - name: describe_info
        - name: duplicate_check # after duplicates have been removed
        - name: boxplots
          params:
            exclude_columns: [ 'Id', 'AppId', 'Name', 'Type',
                               'Current_Players_Last_Updated', 'Release_Date', 'Genres', 'Platforms',
                               'Categories', 'Supported_Languages', 'Review_Score_Desc']
            filename: "boxplots_before_log_transform.png"
        - name: dython_correlation_matrix #NOTE: Execute feature engineering before this step so that we can see correlations for temporal data
          params:
            exclude_columns: [ 'Release_Date']
            annot: true
            cmap: "coolwarm"
            max_rows: 10000
            #log_transform_columns: [ 'Current_Players', 'Total_Reviews', 'Total_Negative', 'Total_Negative', 'Recommendations' ]
            filename: "correlation_matrix_before_log_transform.png"
        - name: class_balance
          params:
            exclude_columns: [ 'Id', 'AppId', 'Name', 'Type', 'URL', 'Metacritic_URL', 'Release_Date', 'Current_Players_Last_Updated']
            label_max_chars: 10
            top_n: 15
            filename: "class_balance_before_log_transform.png"
            #log_transform_columns: ['Current_Players', 'Total_Reviews', 'Total_Positive', 'Total_Negative', 'Recommendations' ]

       # EDA After Log Transform
        - name: boxplots
          params:
            exclude_columns: [ 'Id', 'AppId', 'Name',
                               'Current_Players_Last_Updated', 'Release_Date', 'Genres', 'Platforms',
                               'Categories', 'Supported_Languages', 'Review_Score_Desc' ]
            log_transform_columns: ['Current_Players', 'Total_Reviews', 'Total_Positive', 'Total_Negative', 'Recommendations' ]
            filename: "boxplots_after_log_transform.png"

        - name: dython_correlation_matrix #NOTE: Execute feature engineering before this step so that we can see correlations for temporal data
          params:
            #exclude_columns: [ 'Id', 'AppId',  'Name', 'Type', 'URL', 'Metacritic_URL', 'Current_Players_Last_Updated', 'Release_Date']
            exclude_columns: ['Release_Date']
            annot: true
            cmap: "coolwarm"
            log_transform_columns: ['Current_Players', 'Total_Reviews', 'Total_Negative', 'Total_Negative', 'Recommendations' ]
            max_rows: 10000
            filename: "correlation_matrix_after_log_transform.png"
        - name: class_balance
          params:
            exclude_columns: [ 'Id', 'AppId', 'Name', 'Type', 'URL', 'Metacritic_URL', 'Release_Date', 'Current_Players_Last_Updated' ]
            label_max_chars: 10
            top_n: 15
            log_transform_columns: ['Current_Players', 'Total_Reviews', 'Total_Positive', 'Total_Negative', 'Recommendations', 'Price_Initial', 'Price_Final' ]
            filename: "class_balance_after_log_transform.png"


  - name: data_cleanup
    type: pipelines.data_cleanup_pipeline.DataCleanupPipeline
    params:
      # cleanup_steps is a list of preprocessors (built via PreprocessorFactory)
      cleanup_steps:
#        - name: explode_columns #only do this after EDA to see correlations
#          params:
#            columns: ['Platforms', 'Categories', 'Supported_Languages', 'Genres']
#            sep: ","
        - name: remove_html_tags
          params:
            columns: ['Supported_Languages']
            br_replace: ', '     # optional: replace <br> with ', ' or use ' / ' etc.
            strip: true           # optional: default true
        - name: log_transform
          params:
            columns: ['Current_Players', 'Total_Reviews', 'Total_Positive', 'Total_Negative', 'Recommendations']
            method: 'log1p'
            shift: true
            suffix: ''  # empty means replace original columns; set to '_log' to persist alongside originals


#  - name: eda
#    type: pipelines.eda_pipeline.EDAPipeline
#    params:
#      save_path: "output/eda"
#      steps:
#        - name: class_balance
#          params:
#            exclude_columns: [ 'Id', 'AppId', 'Type', 'URL', 'Metacritic_URL', 'Release_Date', 'Current_Players_Last_Updated']
#            label_max_chars: 10
#            top_n: 15
#            log_transform_columns: ['Current_Players', 'Total_Reviews', 'Total_Positive', 'Total_Negative', 'Recommendations' ]
#        - name: describe_info
#        - name: duplicate_check
#    dataset:
#      target:  null
#      text_field: "AppID"

#  - name: split_data
#    type: pipelines.data_splitter_pipeline.DataSplitterPipeline
#    params:
#      target_column: "Genre"
#      test_size: 0.2
#      random_state: 42


  - name: preprocessing
    type: pipelines.preprocessing_pipeline.PreprocessingPipeline
    params:
      #text_field: 'Developers'
      preprocessors:
#        - name: lowercase
#          applies_to: text
        - name: temporal_features
          applies_to: data   # <-- important: temporal features operate on the DataFrame
          params:
            date_column: 'Release_Date'
            days_since: true
            prefix: 'release'
            quarter: true
            quarter_format: 'int'
        - name: catalog_count
          applies_to: data
          params:
            columns: ['Developers', 'Publishers']
            sep: ','
            drop_original: false
            prefix: 'catalog_count_'
            agg: 'sum'
        - name: count_features
          applies_to: data
          params:
            columns: ['Publishers', 'Developers']
            sep: ','
            drop_original: true
            prefix: 'num_'

  - name: filter_features # DROP RELEASE DATE AFTER  GENERATING TEMPORAL FEATURES
    type: pipelines.filter_pipeline.FilterPipeline
    filter_features:
      - name: drop_columns
        params:
          columns_to_drop:  ['Release_Date']

  - name: imputation
    type: pipelines.imputer_pipeline.ImputerPipeline
    params:
      imputers:
        - name: simple
          params:
            columns: [ 'Current_Players', 'Platforms', 'Categories', 'Genres', 'Supported_Languages',
                      'Price_Initial', 'Price_Final', 'Price_Discount_Percent', 'Total_Reviews', 'Total_Positive', 'Total_Negative', 'Recommendations',
                      'Metacritic_Score', 'Is_Free', 'release_days_since' ]
            numeric_strategy: 'zero'
            text_strategy: 'UNKNOWN'
        - name: simple
          params:
            columns: [ 'Review_Score' ]
            numeric_strategy: 'mean'
            text_strategy: 'UNKNOWN'

  - name: feature_encoding
    type: pipelines.feature_encoder_pipeline.FeatureEncoderPipeline
    params:
      # Define encoders and the columns they should be applied to. Supported encoder names:
      #   - one_hot / onehot    -> OneHotEncoder (single-label categorical)
      #   - multihot / multi_hot -> MultiHotEncoder (multi-label cells, e.g. comma-separated)
      #   - sklearn_label / label -> SklearnLabelEncoder (integer label encoding)
      encoders:
        - name: multihot
          columns: ['Platforms', 'Supported_Languages', 'Genres', 'Categories']
                    # 'Developers', 'Publishers']
          params:
            sep: ','


  - name: feature_scaling
    type: pipelines.feature_scaler_pipeline.FeatureScalerPipeline
    scaler:
      name: standard
      params:
        with_mean: true
        with_std: true
      columns: ['Current_Players', 'Total_Reviews', 'Total_Negative', 'Total_Positive', 'Recommendations' ]


#  # anything that changes the shape of the data will need to be in this cleanup block
#  - name: data_cleanup
#    type: pipelines.data_cleanup_pipeline.DataCleanupPipeline
#    params:
#      # cleanup_steps is a list of preprocessors (built via PreprocessorFactory)
#      cleanup_steps:
#        - name: remove_duplicates
#          params:
#            field: "gameID"
#            keep: "first"
#            case_sensitive: false
#            dropna: true
##        - name: filter_rows
##          params:
##            field: "Genre"
##            values: [ "All" ]
##            operator: "equals"
##            case_sensitive: false
#        - name: filter_rows
#          params:
#            field: "Description"
#            values: [null, ""]
#            operator: "in"
#            case_sensitive: false
#        - name: merge_features
#          params:
#            columns: ["Description", "Title"]
#            merge_to: "Description"
#        - name: remove_urls
#          params:
#            field: "Description"
#            pattern: 'https?://\S+|www\.\S+'
#        - name: remove_repeated_characters
#          params:
#            field: "Description"
#            pattern: "(.)\\1{2,}"
#        - name: remove_punctuation_noise
#          params:
#            field: "Description"
#            pattern: '([!?.,])\1+'
#        - name: remove_whitespace
#          params:
#            field: "Description"
#        - name: stopword_remover
#          params:
#            language: "english"
#            lower: true
#            field: "Description"

#------------------------------------------------------------
# Clustering
#------------------------------------------------------------
  - name: clustering_euclidean
    type: pipelines.clustering_pipeline.ClusteringPipeline
    params:
#      text_field: "Description"
#      genre_field: "Genre"
#      filter_genre: "All"
#      vectorizer:
#        vectorizer_name: "tfidf"
#        vectorizer_field: "Description"
#        vectorizer_params:
#          max_features: 10000
#          ngram_range: [ 4, 6 ]
#          analyzer: "char_wb"
      clusterer:
         name: "hdbscan"
         params:
            min_cluster_size: 50
            min_samples: 25
            #metric: "cosine" # memory issues with cosine on large datasets
            #algorithm: "brute"
            metric: "euclidean" # memory issues... try euclidean
      reducer:
        - name: truncated_svd
          params:
            n_components: 5
            random_state: 42
        - name: "umap"
          params:
            n_components: 5
            n_neighbors: 15
      visualisations:
         name: cluster_plot
         params:
            output_dir: "output/clustering_euclidean"
            figsize: [10, 8]
            xlabel: "UMAP Dimension 1"
            ylabel: "UMAP Dimension 2"
            zlabel: "UMAP Dimension 3"
            title: "HDBSCAN Clustering of Steam Games"
            xticks_rotation: 45
            label_min_cluster_size: 250
            dimensions: 3
